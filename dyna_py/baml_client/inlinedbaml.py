# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CerebrasGptOss120b {\n  provider openai-generic\n  options {\n    model \"gpt-oss-120b\"\n    base_url \"https://api.cerebras.ai/v1\"\n    api_key CEREBRAS_API_KEY\n  }\n}\n\nclient<llm> CustomO3Mini {\n  provider openai\n  options {\n    model \"o3-mini\"\n    api_key env.OPENAI_API_KEY\n    temparature 1.0\n  }\n}\n\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n    temperature 1.0\n  }\n}\n\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomRoundRobin {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomO3Mini, CustomGPT4o, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4o]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    mutliplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.205.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n\n",
    "jockular.baml": "enum GenericStepOutStatus {\n    OK \n    ERR   \n}\nenum GenericStepOutControl {\n    CONTINUE\n    PAUSE\n    STOP \n    DONE\n}\n\nclass StepFrameIn {\n    context string @description(#\"\n        This is an json encoded string input field to provide exact context of the task at hand. \n    \"#)\n    guidance string @description(#\"\n        This is an json encoded string input field and it will provide you additional guidance on a mutiple step workflow if required. \n    \"#)\n}\n\nclass StepFrameOut {\n        \n    status GenericStepOutStatus? @description(#\"\n        This is the status of the request. Generally ok.\n    \"#)\n    control GenericStepOutControl? @description(#\"\n        This is to give you some agency to indicate to an outside loop that is \n        controlling your excecution on whether to continue, pause, stop or be done.\n\n        Most of time your response would be to continue. \n        If anything else than continue, you will need to provide a reason\n        If it is pause, you would also populate hints to indicate when to resume        \n    \"#)\n    reason string? @description(#\"\n        if the decision is anything other than continue, then give reason.\n    \"#)\n    hint string? @description(#\"\n        if the control is pause, then give some hint when to resume.\n    \"#)\n\n    text string? @description(#\"\n        this is the human readable output \n    \"#)\n    payload string? @description(#\"\n        this is the structured output.\n    \"#)\n    context_delta string? @description(#\"\n        You have been provided with some context and some guidance. \n        This is your interpretation of the consolidated context. \n        In the next iteration, this will be the changed context with no additional guidance IF this is different than the original context.\n    \"#)\n\n}\n\n\n\nfunction TellAJokeV2(in_arg:StepFrameIn)->StepFrameOut {\n    client CustomGPT4oMini\n    prompt #\"\n        Tell a joke about {{in_arg.context}} with following guidance if any: {{in_arg.guidance}}.\n\n        {{ctx.output_format}}\n\n\n    \"#\n}\n\n",
    "meta.baml": "enum RegisteredWindow {\n    AgentConfigsWindow @description(#\"\n        This is the window that let you add / update / delete different types of agents including JokeAgent \n        and PersonaAgent\n    \"#)\n    AgentsListWindow @description(#\"\n        This is the window that lets you see all the different agents that you can act on.\n    \"#)\n\n    ConversationsWindow @description(#\"\n        This is the window that lets you see all the conversations associated in a multi-agent scenario.\n    \"#)\n}\n\nfunction GetRegisteredWindow(in_arg: string) -> RegisteredWindow {\n    client CustomGPT4o\n    prompt #\"\n        This returns the registered window from a given string.\n        {{ctx.output_format}}\n\n        ---- GIVEN STRING ---\n        {{in_arg}}\n        ---- END GIVEN STRING ---\n        \n    \"#\n}",
    "ragger.baml": "function Hello(inp_txt:string) -> string {\n  client CustomGPT4oMini\n  prompt #\"\n    Say something in response to input text\n    {{ctx.output_format}}\n\n    --------------\n    {{inp_txt}}\n    --------------\n  \"#\n}\n\nclass Response {\n  can_the_question_be_answered bool @description(#\"\n    ability of the question to be answered in the given context\n  \"#)\n  raionale string @description(#\"\n    why the question can be answered or not\n  \"#)\n}\nfunction RAG(question: string, context: string) -> Response {\n  client \"openai/gpt-4o\"\n  prompt #\"\n    Answer the question in full sentences using the provided context.\n    Do not make up an answer. If the information is not provided in the context, say so clearly. \n    Take some reasonable liberty with context. However do not interject your own knowledge. \n    If there's some background provided, use that to see if the context matches.\n    Also if the context is more specific than the question, that is irrelevant.\n    If there is something that matches the question, please mention that and do not provide further elaboration.\n    \n    QUESTION: {{ question }}\n    RELEVANT CONTEXT: {{ context }}\n    {{ ctx.output_format }}\n      \"# \n}\n\n",
    "tasks.baml": "enum ExecutionMode {\n    Sequential\n    Parallel\n    @@dynamic\n}\n\n\nenum CompletionPolicy {\n    AllSubtasks\n    AnySubtask\n    KOfN\n    @@dynamic\n}\n\nclass Port {\n    name string\n    type string @description(#\"Builtin (e.g., 'String', 'Int', 'JSON') or a custom class name\"#)\n    required bool?\n}\n\nclass Completion {\n    policy CompletionPolicy       @description(#\"AllSubtasks=AND; AnySubtask=OR; KOfN=quorum\"#)\n    k int?                        @description(#\"Used only when policy=KOfN; 1..N of direct subtasks\"#)\n}\n\n\nclass Task {\n    id string\n    title string?\n    description string?\n\n    executionMode ExecutionMode   @description(#\"How this task runs its direct subtasks\"#)\n    subtasks Task[]?               @description(#\"Recursive; array order = execution order when Sequential\"#)\n    dependsOn string[]?           @description(#\"Cross-task deps by id (can point anywhere in the graph)\"#)\n\n    inputPorts Port[]?\n    outputPorts Port[]?\n\n    completion Completion?        @description(#\"Defaults to AllSubtasks if omitted\"#)\n\n    agentId string?               @description(#\"Automation/agent/tool ID\"#)\n\n    guard string?                 @description(#\"Boolean expression gating execution\"#)\n}\n\nclass DataEdge  { \n    fromTaskId string\n    fromPort string\n    toTaskId string\n    toPort string\n}\n\nclass TaskGraph {\n    tasks Task[]                  @description(#\"All tasks (can include multiple roots)\"#)\n    roots string[]?               @description(#\"Optional; else infer as tasks with no inbound deps\"#)\n    edges DataEdge[]?             @description(#\"Typed dataflow across tasks; also implies ordering. An edge also implies a dependency from fromTaskId to toTaskId\"#)\n}\n\nfunction GenerateTaskGraph(in_arg: string) -> TaskGraph {\n    client CustomGPT4oMini\n    prompt #\"\nYou are a task graph planner. Produce a valid TaskGraph for the given instruction.\n\n# Rules:\n\nReturn only a TaskGraph object, no extra text.\ntasks: every task must have a unique id. Use short, stable, kebab-case IDs derived from titles.\nUse executionMode=Sequential when steps must happen in order; use Parallel when independent work can run concurrently.\nCompletion defaults to AllSubtasks if omitted. For KOfN, set a valid k (1..len(subtasks)); otherwise do not use KOfN.\nUse dependsOn for cross-branch requirements. If you use DataEdge, it implies a dependency; do not also duplicate it in dependsOn.\nDeclare inputPorts/outputPorts only when you connect tasks with DataEdge; ensure port types match exactly.\nKeep the graph concise. Prefer 3–8 tasks unless the instruction clearly requires more.\nAvoid empty arrays by omitting fields when not needed (e.g., subtasks, inputPorts, outputPorts, edges).\nSet agentId only if the instruction suggests an automation/tool.\n\n\n# Output shape:\n\nroots: include top-level task IDs (those with no inbound deps).\nedges: optional; include only if modeling typed data flow.\nUse these heuristics:\n\nWords like “in parallel”, “simultaneously”, “while”, “at the same time” → Parallel subtasks.\nIndependent API calls or per-region/per-platform work → Parallel.\nReviews/approvals after production steps → Sequential.\n# Now generate the TaskGraph.\n\n        {{ctx.output_format}}\n        ------ GIVEN instruction ------\n        {{in_arg}}\n        ------ END GIVEN  instruction ------\n        \n    \"#\n}\n\nenum TaskType {\n    NA @description(#\"\n        Not applicable\n    \"#)\n    TRANSLATION @description(#\"\n        only the act of translating from one language into another.\n    \"#)\n    LOCALIZATION @description(#\"\n        only the task of localzing content from one language into another\n    \"#)\n}\n\nclass ConstrainedTask {\n    id string\n    title string?\n    description string?\n    taskType TaskType\n\n    executionMode ExecutionMode   @description(#\"How this task runs its direct subtasks\"#)\n    subtasks ConstrainedTask[]               @description(#\"Recursive; array order = execution order when Sequential\"#)\n    dependsOn string[]?           @description(#\"Cross-task deps by id (can point anywhere in the graph)\"#)\n\n    inputPorts Port[]?\n    outputPorts Port[]?\n\n    completion Completion?        @description(#\"Defaults to AllSubtasks if omitted\"#)\n\n    agentId string?               @description(#\"Automation/agent/tool ID\"#)\n\n    guard string?                 @description(#\"Boolean expression gating execution\"#)\n}\n\nclass ConstrainedTaskGraph {\n    tasks ConstrainedTask[]?                  @description(#\"All tasks (can include multiple roots)\"#)\n    roots string[]?               @description(#\"Optional; else infer as tasks with no inbound deps\"#)\n    edges DataEdge[]?             @description(#\"Typed dataflow across tasks; also implies ordering\"#)\n}\n\nfunction GenerateConstrainedTaskGraph(in_arg: string) -> ConstrainedTaskGraph {\n    client CustomGPT4oMini\n    prompt #\"\n        Generate the execution path for the given string. If the main task is not applicable there is no need to generate subtasks\n        {{ctx.output_format}}\n        ------ GIVEN STRING ------\n        {{in_arg}}\n        ------ END GIVEN STRING ------        \n    \"#\n}\n",
}

def get_baml_files():
    return _file_map